# Chat com RAG (Retrieval Augmented Generation)

Sistema de chat inteligente que permite conversar sobre transcri√ß√µes usando IA com contexto completo.
Agora com **busca vetorial (embeddings + pgvector)** para recuperar os segmentos mais relevantes.

## üéØ Funcionalidades Implementadas

### ‚úÖ RAG (Retrieval Augmented Generation)
- **Contexto da Transcri√ß√£o**: Inclui segmentos relevantes da transcri√ß√£o no prompt
- **Hist√≥rico do Chat**: Mant√©m contexto das mensagens anteriores (√∫ltimas 20)
- **Cita√ß√µes Autom√°ticas**: Extrai timestamps mencionados e cria cita√ß√µes
- **Modelo**: `gpt-4o-mini` (r√°pido e econ√¥mico)
- **Busca Vetorial**: usa `pgvector` para selecionar os segmentos mais similares √† pergunta

### ‚úÖ Gest√£o de Threads
- Cada transcri√ß√£o pode ter m√∫ltiplas conversas (threads)
- Thread criado automaticamente na primeira mensagem
- Soft delete de threads (mant√©m hist√≥rico)

### ‚úÖ Tracking de Uso
- Registra automaticamente uso de IA via `AiUsageService`
- Rastreia: tokens, custo, modelo, usu√°rio
- CallName: `transcription.chat`

## üîå Endpoints

### 1. **Listar Threads**
```http
GET /transcriptions/:transcriptionId/chat/threads
```

**Resposta:**
```json
{
  "data": [
    {
      "id": "uuid",
      "transcriptionId": "uuid",
      "title": null,
      "createdAt": "2026-02-07T..."
    }
  ]
}
```

### 2. **Listar Mensagens de um Thread**
```http
GET /transcriptions/:transcriptionId/chat/threads/:threadId/messages
```

**Resposta:**
```json
{
  "data": [
    {
      "id": "uuid",
      "role": "user",
      "message": "Qual foi o principal tema discutido?",
      "citations": null,
      "createdAt": "2026-02-07T..."
    },
    {
      "id": "uuid",
      "role": "assistant",
      "message": "O principal tema foi... [00:05:23]",
      "citations": [
        {
          "segmentId": "123",
          "startTime": "00:05:23",
          "endTime": "00:05:45",
          "snippet": "Trecho do texto mencionado..."
        }
      ],
      "createdAt": "2026-02-07T..."
    }
  ]
}
```

### 3. **Enviar Mensagem (Chat)**
```http
POST /transcriptions/:transcriptionId/chat/messages
Content-Type: application/json

{
  "message": "Qual foi o principal tema discutido?",
  "threadId": "uuid-opcional"
}
```

**Resposta:**
```json
{
  "threadId": "uuid",
  "assistant": {
    "message": "O principal tema foi...",
    "citations": [
      {
        "segmentId": "123",
        "startTime": "00:05:23",
        "endTime": "00:05:45",
        "snippet": "Trecho..."
      }
    ]
  }
}
```

**Observa√ß√µes:**
- Se `threadId` n√£o for fornecido, cria um novo thread automaticamente
- Se fornecido, continua a conversa no thread existente
- A resposta inclui o `threadId` para futuras mensagens

### 4. **Deletar Thread**
```http
DELETE /transcriptions/:transcriptionId/chat/threads/:threadId
```

**Resposta:**
```json
{
  "ok": true,
  "message": "Thread deletado com sucesso"
}
```

**Caracter√≠sticas:**
- ‚úÖ Soft delete (mant√©m dados para auditoria)
- ‚úÖ Remove thread e torna mensagens inacess√≠veis
- ‚úÖ Valida propriedade (somente dono da transcri√ß√£o)

## üß† Como Funciona o RAG

### 1. Prepara√ß√£o do Contexto

```typescript
// 1. Busca segmentos relevantes da transcri√ß√£o (at√© 50)
const relevantSegments = getRelevantSegments(transcription, userMessage, 50);

// 2. Busca hist√≥rico de mensagens anteriores (√∫ltimas 20)
const historyMessages = await findPreviousMessages(threadId, 20);

// 3. Monta contexto formatado
const context = {
  transcri√ß√£o: "t√≠tulo, dura√ß√£o, segmentos...",
  hist√≥rico: "conversas anteriores...",
  pergunta: "pergunta atual do usu√°rio"
};
```

### 2. Prompt Estruturado

```
Voc√™ √© um assistente especializado em analisar transcri√ß√µes de √°udio/v√≠deo.

# TRANSCRI√á√ÉO
T√≠tulo: Reuni√£o de Planejamento
Dura√ß√£o: 1800s

## Trechos:
[00:00:15 - 00:00:23] Jo√£o: Bom dia a todos...
[00:00:25 - 00:00:45] Maria: Vamos come√ßar...
...

# HIST√ìRICO DA CONVERSA
Usu√°rio: Quem participou da reuni√£o?
Assistente: Participaram Jo√£o e Maria...

# INSTRU√á√ïES
- Responda APENAS com base na transcri√ß√£o fornecida
- Cite timestamps espec√≠ficos [HH:MM:SS]
- Seja direto e objetivo

# PERGUNTA DO USU√ÅRIO
Qual foi o principal tema discutido?
```

### 3. Gera√ß√£o da Resposta

```typescript
const response = await aiOrchestrator.generateStrictText(prompt, 'gpt-4o-mini', {
  maxTokens: 1000,
  temperature: 0.7,
  userId,
  callName: 'transcription.chat',
});
```

### 4. Extra√ß√£o de Cita√ß√µes

```typescript
// Busca timestamps [HH:MM:SS] na resposta
const timestampRegex = /\[(\d{1,2}:\d{2}:\d{2})\]/g;
const matches = response.matchAll(timestampRegex);

// Cria cita√ß√µes com os segmentos correspondentes
for (const match of matches) {
  const segment = findSegmentByTimestamp(match[1]);
  citations.push({
    segmentId: segment.id,
    startTime: segment.startTime,
    endTime: segment.endTime,
    snippet: segment.text.slice(0, 200)
  });
}
```

## üìä Monitoramento de Uso

Toda intera√ß√£o √© registrada automaticamente:

```typescript
await aiUsage.record({
  kind: 'chat.completions.text',
  model: 'gpt-4o-mini',
  userId,
  callName: 'transcription.chat',
  promptTokens: 1234,
  completionTokens: 567,
  cachedTokens: 100,
  totalTokens: 1801,
});
```

Consulte uso via:
```http
GET /ai-usage?callName=transcription.chat
GET /ai-usage?userId=uuid&callName=transcription.chat
```

## üîÑ Fluxo Completo de Uma Conversa

```
1. Usu√°rio envia primeira mensagem
   POST /transcriptions/:id/chat/messages
   { "message": "Sobre o que √© esta transcri√ß√£o?" }
   
2. Sistema:
   - Cria novo thread automaticamente
   - Busca segmentos da transcri√ß√£o
   - Monta prompt com contexto
   - Envia para LLM (gpt-4o-mini)
   - Extrai cita√ß√µes da resposta
   - Salva mensagens (user + assistant)
   - Registra uso de IA
   
3. Usu√°rio continua conversa
   POST /transcriptions/:id/chat/messages
   { "message": "Me fale mais sobre isso", "threadId": "uuid" }
   
4. Sistema:
   - Busca thread existente
   - Carrega hist√≥rico (√∫ltimas 20 mensagens)
   - Inclui hist√≥rico no prompt
   - Mant√©m contexto da conversa
   - Gera resposta considerando hist√≥rico
```

## üöÄ Melhorias Futuras

### Busca Sem√¢ntica
Atualmente retorna os primeiros N segmentos. Melhorias poss√≠veis:

```typescript
// TODO: Implementar busca vetorial
private async getRelevantSegments(
  transcription: Transcriptor,
  userMessage: string,
  limit = 50,
) {
  // 1. Gerar embedding da pergunta
  const questionEmbedding = await generateEmbedding(userMessage);
  
  // 2. Buscar segmentos mais similares (cosine similarity)
  const segments = await vectorSearch(questionEmbedding, limit);
  
  return segments;
}
```

### T√≠tulo Autom√°tico do Thread
```typescript
// TODO: Gerar t√≠tulo baseado na primeira mensagem
async generateThreadTitle(firstMessage: string): Promise<string> {
  return aiOrchestrator.generateStrictText(
    `Gere um t√≠tulo curto (m√°x 50 chars) para uma conversa que come√ßa com: "${firstMessage}"`,
    'gpt-4o-mini'
  );
}
```

### Cache de Embeddings
- Pr√©-calcular embeddings dos segmentos
- Armazenar em banco vetorial (pgvector, Pinecone, etc)
- Busca muito mais r√°pida

### Vari√°veis de ambiente (novas)

```bash
# modelo de embedding (1536 dims)
AI_EMBEDDING_MODEL=text-embedding-3-small

# topK de segmentos similares
AI_RAG_TOP_K=10

# janela de contexto (¬±N segmentos a partir do topK)
AI_RAG_WINDOW=2

# concorr√™ncia para indexa√ß√£o de embeddings
AI_EMBEDDING_CONCURRENCY=4
```

### Streaming de Respostas
```typescript
// TODO: Implementar SSE para streaming
async *chatStream(userId, transcriptionId, dto) {
  const stream = await openai.chat.completions.create({
    stream: true,
    // ...
  });
  
  for await (const chunk of stream) {
    yield chunk.choices[0]?.delta?.content || '';
  }
}
```

## ‚öôÔ∏è Configura√ß√£o

Vari√°veis de ambiente relevantes:

```bash
# Chave da OpenAI (obrigat√≥ria)
OPENAI_API_KEY=sk-...

# Limites de prompt
AI_PROMPT_CHAR_LIMIT=120000

# Timeouts
AI_TIMEOUT_MS=20000

# Modelo padr√£o
AI_CHECKLIST_MODEL=gpt-4o-mini

# Auditoria de prompts
AI_LOG_PROMPTS=1
AI_LOG_DIR=./storage/ai-prompts
```

## üîí Seguran√ßa

- ‚úÖ Autentica√ß√£o JWT obrigat√≥ria
- ‚úÖ Valida√ß√£o de propriedade (userId)
- ‚úÖ Soft delete (auditoria completa)
- ‚úÖ Rate limiting via guards do NestJS
- ‚úÖ Logs de auditoria autom√°ticos

## üìù Exemplos de Uso

### Perguntas T√≠picas

**Resumo:**
```
"Me fa√ßa um resumo desta transcri√ß√£o"
"Quais foram os principais pontos discutidos?"
```

**Busca Espec√≠fica:**
```
"Em que momento falaram sobre o projeto X?"
"Quem mencionou o prazo de entrega?"
```

**An√°lise:**
```
"Quais foram as decis√µes tomadas?"
"Houve algum conflito ou discord√¢ncia?"
```

**Contexto:**
```
"O que foi dito antes de [00:15:30]?"
"Quem respondeu √† pergunta da Maria?"
```

### Conversas Contextuais

```
User: Sobre o que √© esta reuni√£o?
AI: Esta √© uma reuni√£o de planejamento do Q1 2026...

User: Quem participou?
AI: Participaram Jo√£o (gerente), Maria (desenvolvedora)...

User: O que Jo√£o disse sobre prazos?
AI: Jo√£o mencionou em [00:15:23] que os prazos s√£o apertados...
```

## üêõ Tratamento de Erros

```typescript
try {
  assistantText = await aiOrchestrator.generateStrictText(...);
} catch (error) {
  logger.error(`[Chat RAG] Erro: ${error?.message}`);
  assistantText = 'Desculpe, ocorreu um erro. Tente novamente.';
}
```

Erros comuns:
- `OPENAI_API_KEY n√£o configurada`
- `AI_REQUEST_TIMEOUT` (timeout de 20s)
- `EMPTY_MODEL_OUTPUT` (resposta vazia do modelo)
- `JSON_PARSE_ERROR` (erro de parsing - n√£o aplic√°vel a texto)
